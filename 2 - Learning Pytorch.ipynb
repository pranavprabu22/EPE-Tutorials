{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Learning Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was made in collaboration with Aaron Wang and used his work with Pytorch models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to install the Pytorch package before going through this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c678d52588d3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c678d52588d3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install torch torchvision\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#To install Pytorch, type this into your terminal:\n",
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages and open the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08634c0f2acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file using the h5py package, and use pandas to make a set that contains all of the features and labels (types of jets), while setting the training values using the provided method from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z', 'r')#Opens file\n",
    "treeArray = f['t_allpar_new'][()]#Accesses dataset\n",
    "\n",
    "features = ['j_zlogz', 'j_c1_b0_mmdt','j_c1_b1_mmdt', 'j_c1_b2_mmdt' , 'j_c2_b1_mmdt',\n",
    "            'j_c2_b2_mmdt', 'j_d2_b1_mmdt', 'j_d2_b2_mmdt', 'j_d2_a1_b1_mmdt', 'j_d2_a1_b2_mmdt', 'j_m2_b1_mmdt', 'j_m2_b2_mmdt', 'j_n2_b1_mmdt', \n",
    "            'j_n2_b2_mmdt', 'j_mass_mmdt', 'j_multiplicity']#All the features need to train\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']#Types of jets that will be used for the training\n",
    "features_labels_df = pd.DataFrame(treeArray, columns = features + labels)#Makes set with only the values for the features and labels\n",
    "features_labels_df = features_labels_df.drop_duplicates()\n",
    "features_val = features_labels_df[features].values\n",
    "\n",
    "labels_val = features_labels_df[labels].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_val,labels_val,test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input shape to base the layers off of using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Pytorch model using the Sequential model, by creating multiple Linear layers (4 layers in this case) with a ReLU activation and an output Softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(16,64),#Input layer with the shape being 16 nodes\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16,5),\n",
    "    torch.nn.Softmax())#Output layer for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the model, load the training sets for the model to train and produce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4#Controls the rate at which the model learns and trains based on the set\n",
    "dataloader = DataLoader(X_train, batch_size=64, shuffle=False, sampler=None,#Loading the input training set\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)\n",
    "ydataloader = DataLoader(y_train, batch_size=64, shuffle=False, sampler=None,#Loading the expected output training set for comparison\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the kind of loss to be plotted to see the effectiveness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()#Also known as log loss, measures the performance of a classification model whose output is a probability value between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss = np.zeros(100)\n",
    "valloss = np.zeros(100)\n",
    "for t in range(100):\n",
    "    for x,y in zip(dataloader,ydataloader):\n",
    "        y_pred = model(x.float())\n",
    "\n",
    "        loss = loss_fn(y_pred, torch.max(y.float(),1)[1])\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        trainloss[t] = loss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad\n",
    "    y_pred = model(torch.from_numpy(X_test))\n",
    "    yloss = loss_fn(y_pred, torch.max(torch.from_numpy(y_test),1)[1])\n",
    "    valloss[t] = yloss\n",
    "    print('Epoch' +' ' +str(t) + ' Train Loss:' +str(trainloss[t]))\n",
    "    print('        ' + 'Val Loss:' + str(valloss[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the method to plot the loss per epoch during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(trainloss,valloss):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(trainloss)\n",
    "    plt.plot(valloss)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model loss over the epochs using the method you just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurve(trainloss,valloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make a ROC curve and compare the results of the five-tagger survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels_val, labels, model, outputDir='', outputSuffix=''):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    labels_pred = model(torch.from_numpy(features_val))\n",
    "    df = pd.DataFrame()\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    plt.figure(figsize=(10,8))       \n",
    "    g = labels_pred.detach().numpy()\n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = g[:,i]\n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label],tpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.plot([0, 1], [0, 1], lw=1, color='black', linestyle='--')\n",
    "    #plt.semilogy()\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,'DNN ROC Curve',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = makeRoc(X_test, y_test, labels, model, outputSuffix='two-layer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
